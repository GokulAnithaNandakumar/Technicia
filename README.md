# Gesture Controlled OS ![Windows](https://img.shields.io/badge/Windows-Latest-blue)  ![Python](https://img.shields.io/badge/Python-3.9.7-blue)
## Team SpongeBob

Gesture Controlled Virtual Mouse makes human-computer interaction simple by utilizing Hand Gestures. The computer requires almost no direct contact, and all input/output operations can be virtually controlled using static and dynamic hand gestures. This project leverages state-of-the-art Machine Learning and Computer Vision algorithms to recognize hand gestures and voice commands, providing smooth interaction without any additional hardware requirements. It consists of two modules: one which directly works on hands using MediaPipe Hand detection, and the other which makes use of gloves of any uniform color. Currently, it works on the Windows platform.

### Future Applications
1. **Hospital Surgery Room**: Surgeons can control vital monitors for patients' data history without contaminating gloves, ensuring a sterile environment during surgeries.
2. **Billing & Restaurant Kiosks**: Users can navigate through billing kiosks in public spaces without physically touching the screen, enhancing hygiene and reducing the spread of germs.
3. **Car Infotainment System**: Drivers and passengers can control various functions of the car's infotainment system through hand gestures, allowing for safer and more convenient operation while driving.

### Features included: 
 - Hand gesture enabled mouse control, with clicks
 - Select and drag elements
 - Volume and brightness controls
 - Screen scroll
 - Demo Shopping interface [Here](https://github.com/GokulAnithaNandakumar/Technicia/blob/main/Shopping/src/DragDrop.html) 
 - Powerpoint controls [Here](https://github.com/GokulAnithaNandakumar/Technicia/blob/main/Powerpoint/powerpoint.py)
![Screenshot 2024-03-16 030855](https://github.com/GokulAnithaNandakumar/Technicia/assets/112749784/64b86d2a-5858-43a9-a8d0-a1b2aaf324d4)
![Screenshot 2024-03-16 030910](https://github.com/GokulAnithaNandakumar/Technicia/assets/112749784/edda3903-ffe4-4aa1-bc0a-501a0541058f)




### Frameworks, Libraries, and Technologies Used
- ![MediaPipe](https://img.shields.io/badge/MediaPipe-Latest-blue)
- ![OpenCV](https://img.shields.io/badge/OpenCV-4.5.3-green)
- ![PyAutoGUI](https://img.shields.io/badge/PyAutoGUI-0.9.52-orange)
- ![Math](https://img.shields.io/badge/Math-Standard-yellow)
- ![PyCaw](https://img.shields.io/badge/PyCaw-Latest-lightgrey)
- ![Screen Brightness Control](https://img.shields.io/badge/Screen%20Brightness%20Control-Latest-brightgreen)
- ![Enum](https://img.shields.io/badge/Enum-Latest-red)
- ![ctypes](https://img.shields.io/badge/ctypes-Latest-blueviolet)
- ![comtypes](https://img.shields.io/badge/comtypes-Latest-yellowgreen)


### Instructions for Running
To run the Gesture Controlled OS, follow these steps:

1. Ensure you have all necessary libraries installed (MediaPipe, OpenCV, PyAutoGUI, etc.).
2. Clone the repository to your local machine.
3. Navigate to the directory containing the code.
4. Run the Python script.
5. Position your hands in front of the camera and perform gestures to control the OS.

### Contributors
This project was developed by Team Spongebob during a hackathon.

- Vijay Varadharajan
- Santhosh Kumar S P
- Goutham Kurapati
- Gokul

For any inquiries or issues, please contact santhoshkumarsp222004@gmail.com .
